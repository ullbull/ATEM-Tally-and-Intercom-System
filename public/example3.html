<!DOCTYPE html>
<!--
 Copyright 2020 Google LLC

 Licensed under the Apache License, Version 2.0 (the "License");
 you may not use this file except in compliance with the License.
 You may obtain a copy of the License at

      http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing, software
 distributed under the License is distributed on an "AS IS" BASIS,
 WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 See the License for the specific language governing permissions and
 limitations under the License.
-->

<html>

<head>
    <meta charset="utf-8" />
    <title>RecordRTC over Socket.io</title>

    <meta http-equiv="content-type" content="text/html; charset=utf-8" />

    <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">
    <link rel="stylesheet" href="https://code.getmdl.io/1.3.0/material.indigo-pink.min.css">

    <script src="https://www.WebRTC-Experiment.com/RecordRTC.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/socket.io/2.3.0/socket.io.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/socket.io-stream/0.9.1/socket.io-stream.js"></script>
</head>

<body>
    <script src="/socket.io/socket.io.js"></script>
    <script src="/js/socket.io-stream.js"></script>
    <!-- <audio id="mic" autoplay></audio> -->

    <div style="margin: 20px">
        <h1 style="font-size: 18px;">Example 3: Dialogflow Speech Intent Detection with Text to Speech output</h1>

        <div>
            <button id="start-recording" disabled>Start Recording</button>
            <button id="stop-recording" disabled>Stop Recording</button>
        </div>

        <h2 style="font-size: 14px;">Results: data[0].outputAudio</h2>
        <p>Make sure your speakers are turned on.</p>
    </div>

    <script type="text/javascript">
        const micElement = document.getElementById('mic');

        const socketio = io();
        const socket = socketio.on('connect', function () {
            // reset the recorder
            startRecording.disabled = false;
        });

        // when the server found results send
        // it back to the client
        const resultpreview = document.getElementById('results');
        socketio.on('results', function (data) {
            console.log(data);
            console.log(data[0].outputAudio);
            playOutput(data[0].outputAudio);
        });

        const startRecording = document.getElementById('start-recording');
        const stopRecording = document.getElementById('stop-recording');
        let recordAudio;

        // on start button handler
        startRecording.onclick = function () {
            // recording started
            startRecording.disabled = true;

            // make use of HTML 5/WebRTC, JavaScript getUserMedia()
            // to capture the browser microphone stream
            navigator.getUserMedia({
                audio: true
            }, function (stream) {
                //micElement.srcObject = stream;

                recordAudio = RecordRTC(stream, {
                    type: 'audio',
                    mimeType: 'audio/webm',
                    sampleRate: 44100, // this sampleRate should be the same in your server code

                    // MediaStreamRecorder, StereoAudioRecorder, WebAssemblyRecorder
                    // CanvasRecorder, GifRecorder, WhammyRecorder
                    recorderType: StereoAudioRecorder,

                    // Dialogflow / STT requires mono audio
                    numberOfAudioChannels: 1,

                    // get intervals based blobs
                    // value in milliseconds
                    // as you might not want to make detect calls every seconds
                    timeSlice: 4000,

                    // only for audio track
                    // audioBitsPerSecond: 128000,

                    // used by StereoAudioRecorder
                    // the range 22050 to 96000.
                    // let us force 16khz recording:
                    desiredSampRate: 16000
                });

                recordAudio.startRecording();
                stopRecording.disabled = false;
            }, function (error) {
                console.error(JSON.stringify(error));
            });
        };

        function dataURLtoBlob(dataURL) {
            // convert base64 to raw binary data held in a string
            // doesn't handle URLEncoded DataURIs - see SO answer #6850276 for code that does this
            var byteString = atob(dataURL.split(',')[1]);

            // separate out the mime component
            var mimeString = dataURL.split(',')[0].split(':')[1].split(';')[0]

            // write the bytes of the string to an ArrayBuffer
            var ab = new ArrayBuffer(byteString.length);

            // create a view into the buffer
            var ia = new Uint8Array(ab);

            // set the bytes of the buffer to the correct values
            for (var i = 0; i < byteString.length; i++) {
                ia[i] = byteString.charCodeAt(i);
            }

            // write the ArrayBuffer to a blob, and you're done
            var blob = new Blob([ab], { type: mimeString });

            return blob;
        }

        // on stop button handler
        stopRecording.onclick = function () {
            // recording stopped
            startRecording.disabled = false;
            stopRecording.disabled = true;

            // stop audio recorder
            recordAudio.stopRecording(function () {

                // after stopping the audio, get the audio data
                recordAudio.getDataURL(async function (audioDataURL) {
                    var files = {
                        audio: {
                            type: recordAudio.getBlob().type || 'audio/wav',
                            dataURL: audioDataURL
                        }
                    };
                    // submit the audio file to the server
                    socketio.emit('message', files);

                    let blob = dataURLtoBlob(files.audio.dataURL);
                    let arrayBuffer = await new Response(blob).arrayBuffer();   //=> <ArrayBuffer>
                    playOutput(arrayBuffer);
                });
            });
        };

        /*
      * When working with Dialogflow and Dialogflow matched an intent,
      * and returned an audio buffer. Play this output.
      */
        function playOutput(arrayBuffer) {
            let audioContext = new AudioContext();
            let outputSource;
            try {
                if (arrayBuffer.byteLength > 0) {
                    audioContext.decodeAudioData(arrayBuffer,
                        function (buffer) {
                            audioContext.resume();
                            outputSource = audioContext.createBufferSource();
                            outputSource.connect(audioContext.destination);
                            outputSource.buffer = buffer;
                            outputSource.start(0);
                        },
                        function () {
                            console.log(arguments);
                        });
                }
            } catch (e) {
                console.log(e);
            }
        }
    </script>

</body>

</html>